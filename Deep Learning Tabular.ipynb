{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starts with number....\n",
      "Clickbait Phrases....\n",
      "Clickbait re....\n",
      "Num dots....\n",
      "Text Features....\n",
      "Punctuation....\n",
      "Word ratios....\n",
      "Sentiment Scores....\n",
      "Readability Scores....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02849fe091574f6f8b4a9b1bbaa99ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e577f74c6164b63bae5aa3b78b5b07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Glove.....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980852af28aa44d38690f3ff17403780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b569c5c464405f85f151cdbca33590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from utility_funcitons import *\n",
    "from feature_selection import *\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train_features, test_features, feature_names = featurize(train, test, 'tfidf_glove')\n",
    "\n",
    "y_train = np.where(train.label.values == 'clickbait', 1, 0)\n",
    "y_test = np.where(test.label.values == 'clickbait', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-b160a80dc31b>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-b160a80dc31b>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    def adjusted_f1(y_true, y_prob):/\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "\n",
    "def adjusted_f1(y_true, y_prob):/\n",
    "    f1 = print_model_metrics(y_true, y_prob, verbose = 0, return_metrics = True)[0]\n",
    "    return f1\n",
    "\n",
    "score = make_scorer(adjusted_f1, greater_is_better = True, needs_proba = True)\n",
    "\n",
    "X = sparse.vstack((train_features, test_features))\n",
    "test_fold = [-1 for _ in range(train_features.shape[0])] + [0 for _ in range(test_features.shape[0])]\n",
    "y = np.concatenate([y_train, y_test])\n",
    "ps = PredefinedSplit(test_fold)\n",
    "\n",
    "def run_grid_search(model, params, x_train, y_train):\n",
    "    grid = GridSearchCV(model, params, cv = ps, n_jobs = 4, scoring = score, verbose = 0, refit = False)\n",
    "    grid.fit(x_train, y_train)\n",
    "    return (grid.best_params_, grid.best_score_)\n",
    "\n",
    "\n",
    "def fit_n_times(model, x_train, y_train, x_test, y_test, n_iters = 10):\n",
    "    metrics = np.zeros(5)\n",
    "    for _ in range(n_iters):\n",
    "        model.fit(x_train, y_train)\n",
    "        y_test_prob = model.predict_proba(x_test)[:,1]\n",
    "        metrics += print_model_metrics(y_test, y_test_prob, verbose = False, return_metrics = True)\n",
    "    metrics /=10\n",
    "    print('F1: {:.3f} | Pr: {:.3f} | Re: {:.3f} | AUC: {:.3f} | Accuracy: {:.3f} \\n'.format(*metrics))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 150)               18000     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               15100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,201\n",
      "Trainable params: 33,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.7423 - accuracy: 0.4531\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.85595, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.6795 - accuracy: 0.5694 - val_loss: 0.6062 - val_accuracy: 0.8559\n",
      "Epoch 2/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6304 - accuracy: 0.6875\n",
      "Epoch 00002: val_accuracy improved from 0.85595 to 0.95355, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 0.5758 - accuracy: 0.7842 - val_loss: 0.4792 - val_accuracy: 0.9535\n",
      "Epoch 3/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.5317 - accuracy: 0.8594\n",
      "Epoch 00003: val_accuracy did not improve from 0.95355\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.4783 - accuracy: 0.8531 - val_loss: 0.3821 - val_accuracy: 0.9149\n",
      "Epoch 4/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.4484 - accuracy: 0.8516\n",
      "Epoch 00004: val_accuracy improved from 0.95355 to 0.95580, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3673 - accuracy: 0.9011 - val_loss: 0.2667 - val_accuracy: 0.9558\n",
      "Epoch 5/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.2845 - accuracy: 0.9141\n",
      "Epoch 00005: val_accuracy improved from 0.95580 to 0.95640, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 0.2693 - accuracy: 0.9281 - val_loss: 0.1908 - val_accuracy: 0.9564\n",
      "Epoch 6/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.2389 - accuracy: 0.9453\n",
      "Epoch 00006: val_accuracy improved from 0.95640 to 0.96630, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 0.2089 - accuracy: 0.9371 - val_loss: 0.1388 - val_accuracy: 0.9663\n",
      "Epoch 7/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.2002 - accuracy: 0.9531\n",
      "Epoch 00007: val_accuracy did not improve from 0.96630\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1697 - accuracy: 0.9411 - val_loss: 0.1306 - val_accuracy: 0.9603\n",
      "Epoch 8/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.1167 - accuracy: 0.9609\n",
      "Epoch 00008: val_accuracy improved from 0.96630 to 0.97005, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.1402 - accuracy: 0.9471 - val_loss: 0.1011 - val_accuracy: 0.9700\n",
      "Epoch 9/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.1095 - accuracy: 0.9453\n",
      "Epoch 00009: val_accuracy improved from 0.97005 to 0.97220, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 187ms/step - loss: 0.1190 - accuracy: 0.9590 - val_loss: 0.0908 - val_accuracy: 0.9722\n",
      "Epoch 10/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.1057 - accuracy: 0.9609\n",
      "Epoch 00010: val_accuracy improved from 0.97220 to 0.97445, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 0.1099 - accuracy: 0.9700 - val_loss: 0.0833 - val_accuracy: 0.9744\n",
      "Epoch 11/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0847 - accuracy: 0.9766\n",
      "Epoch 00011: val_accuracy did not improve from 0.97445\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 0.1030 - accuracy: 0.9660 - val_loss: 0.0875 - val_accuracy: 0.9692\n",
      "Epoch 12/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0763 - accuracy: 0.9922\n",
      "Epoch 00012: val_accuracy improved from 0.97445 to 0.97700, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 135ms/step - loss: 0.0880 - accuracy: 0.9730 - val_loss: 0.0726 - val_accuracy: 0.9770\n",
      "Epoch 13/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0640 - accuracy: 0.9922\n",
      "Epoch 00013: val_accuracy improved from 0.97700 to 0.97760, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.0821 - accuracy: 0.9740 - val_loss: 0.0689 - val_accuracy: 0.9776\n",
      "Epoch 14/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.1074 - accuracy: 0.9531\n",
      "Epoch 00014: val_accuracy did not improve from 0.97760\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0828 - accuracy: 0.9740 - val_loss: 0.0760 - val_accuracy: 0.9732\n",
      "Epoch 15/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0850 - accuracy: 0.9766\n",
      "Epoch 00015: val_accuracy improved from 0.97760 to 0.97835, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.0716 - accuracy: 0.9750 - val_loss: 0.0643 - val_accuracy: 0.9783\n",
      "Epoch 16/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0739 - accuracy: 0.9766\n",
      "Epoch 00016: val_accuracy improved from 0.97835 to 0.97875, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 0.0637 - accuracy: 0.9760 - val_loss: 0.0625 - val_accuracy: 0.9787\n",
      "Epoch 17/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0578 - accuracy: 0.9922\n",
      "Epoch 00017: val_accuracy did not improve from 0.97875\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0696 - accuracy: 0.9770 - val_loss: 0.0647 - val_accuracy: 0.9773\n",
      "Epoch 18/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0664 - accuracy: 0.9609\n",
      "Epoch 00018: val_accuracy improved from 0.97875 to 0.97995, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.0618 - accuracy: 0.9730 - val_loss: 0.0577 - val_accuracy: 0.9800\n",
      "Epoch 19/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0693 - accuracy: 0.9844\n",
      "Epoch 00019: val_accuracy improved from 0.97995 to 0.98030, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.0600 - accuracy: 0.9820 - val_loss: 0.0574 - val_accuracy: 0.9803\n",
      "Epoch 20/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0474 - accuracy: 0.9844\n",
      "Epoch 00020: val_accuracy did not improve from 0.98030\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0623 - accuracy: 0.9830 - val_loss: 0.0555 - val_accuracy: 0.9801\n",
      "Epoch 21/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0565 - accuracy: 0.9922\n",
      "Epoch 00021: val_accuracy improved from 0.98030 to 0.98055, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.0564 - accuracy: 0.9820 - val_loss: 0.0557 - val_accuracy: 0.9805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0525 - accuracy: 0.9766\n",
      "Epoch 00022: val_accuracy did not improve from 0.98055\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0501 - accuracy: 0.9810 - val_loss: 0.0591 - val_accuracy: 0.9791\n",
      "Epoch 23/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0361 - accuracy: 0.9844\n",
      "Epoch 00023: val_accuracy did not improve from 0.98055\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0527 - accuracy: 0.9800 - val_loss: 0.0578 - val_accuracy: 0.9790\n",
      "Epoch 24/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.1000 - accuracy: 0.9609\n",
      "Epoch 00024: val_accuracy improved from 0.98055 to 0.98105, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.0445 - accuracy: 0.9870 - val_loss: 0.0524 - val_accuracy: 0.9811\n",
      "Epoch 25/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0791 - accuracy: 0.9688\n",
      "Epoch 00025: val_accuracy did not improve from 0.98105\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0483 - accuracy: 0.9850 - val_loss: 0.0542 - val_accuracy: 0.9809\n",
      "Epoch 26/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0265 - accuracy: 0.9922\n",
      "Epoch 00026: val_accuracy did not improve from 0.98105\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0433 - accuracy: 0.9850 - val_loss: 0.0603 - val_accuracy: 0.9783\n",
      "Epoch 27/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0707 - accuracy: 0.9766\n",
      "Epoch 00027: val_accuracy did not improve from 0.98105\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0530 - accuracy: 0.9820 - val_loss: 0.0597 - val_accuracy: 0.9780\n",
      "Epoch 28/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0363 - accuracy: 0.9766\n",
      "Epoch 00028: val_accuracy did not improve from 0.98105\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0619 - accuracy: 0.9750 - val_loss: 0.0759 - val_accuracy: 0.9722\n",
      "Epoch 29/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0371 - accuracy: 0.9922\n",
      "Epoch 00029: val_accuracy did not improve from 0.98105\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0512 - accuracy: 0.9820 - val_loss: 0.0614 - val_accuracy: 0.9778\n",
      "Epoch 30/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0736 - accuracy: 0.9688\n",
      "Epoch 00030: val_accuracy did not improve from 0.98105\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0453 - accuracy: 0.9850 - val_loss: 0.0583 - val_accuracy: 0.9787\n",
      "Epoch 31/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0404 - accuracy: 0.9844\n",
      "Epoch 00031: val_accuracy did not improve from 0.98105\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.0372 - accuracy: 0.9880 - val_loss: 0.0521 - val_accuracy: 0.9807\n",
      "Epoch 32/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0339 - accuracy: 0.9922\n",
      "Epoch 00032: val_accuracy did not improve from 0.98105\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.0527 - val_accuracy: 0.9805\n",
      "Epoch 33/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0530 - accuracy: 0.9844\n",
      "Epoch 00033: val_accuracy improved from 0.98105 to 0.98160, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.0350 - accuracy: 0.9920 - val_loss: 0.0496 - val_accuracy: 0.9816\n",
      "Epoch 34/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 00034: val_accuracy improved from 0.98160 to 0.98195, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.0344 - accuracy: 0.9930 - val_loss: 0.0489 - val_accuracy: 0.9819\n",
      "Epoch 35/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0335 - accuracy: 0.9844\n",
      "Epoch 00035: val_accuracy did not improve from 0.98195\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0369 - accuracy: 0.9860 - val_loss: 0.0520 - val_accuracy: 0.9806\n",
      "Epoch 36/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 00036: val_accuracy did not improve from 0.98195\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0417 - accuracy: 0.9860 - val_loss: 0.0568 - val_accuracy: 0.9793\n",
      "Epoch 37/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.1103 - accuracy: 0.9844\n",
      "Epoch 00037: val_accuracy did not improve from 0.98195\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0402 - accuracy: 0.9880 - val_loss: 0.0513 - val_accuracy: 0.9808\n",
      "Epoch 38/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 00038: val_accuracy did not improve from 0.98195\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0331 - accuracy: 0.9910 - val_loss: 0.0510 - val_accuracy: 0.9812\n",
      "Epoch 39/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 00039: val_accuracy improved from 0.98195 to 0.98220, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.0340 - accuracy: 0.9880 - val_loss: 0.0482 - val_accuracy: 0.9822\n",
      "Epoch 40/40\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 00040: val_accuracy improved from 0.98220 to 0.98260, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.0325 - accuracy: 0.9890 - val_loss: 0.0480 - val_accuracy: 0.9826\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 40\n",
    "\n",
    "simple_nn = Sequential()\n",
    "simple_nn.add(Dense(150, activation='relu', input_shape=(119,)))\n",
    "simple_nn.add(Dropout(0.2))\n",
    "simple_nn.add(Dense(100, activation='relu'))\n",
    "simple_nn.add(Dropout(0.2))\n",
    "simple_nn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "simple_nn.summary()\n",
    "\n",
    "simple_nn.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('./saved_models', monitor = 'val_accuracy', verbose = 1, save_best_only=True)\n",
    "\n",
    "history = simple_nn.fit(train_features.todense(), y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [checkpoint],\n",
    "                    validation_data=(test_features.todense(), y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.983 | Pr: 0.984 | Re: 0.982 | AUC: 0.998 | Accuracy: 0.983 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "simple_nn = load_model('./saved_models')\n",
    "\n",
    "y_pred_prob = simple_nn.predict(test_features.todense())\n",
    "print_model_metrics(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.983 | Pr: 0.979 | Re: 0.987 | AUC: 0.998 | Accuracy: 0.983 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "svm = SVC(C = 10, kernel = 'poly', degree = 2, probability = True, verbose = 0)\n",
    "\n",
    "svm_bag = BaggingClassifier(svm, n_estimators = 200, max_features = 0.9, max_samples = 1.0, bootstrap_features = False, bootstrap = True, n_jobs = 1, verbose = 0)\n",
    "\n",
    "svm_bag.fit(train_features, y_train)\n",
    "y_test_prob = svm_bag.predict_proba(test_features)[:,1]\n",
    "print_model_metrics(y_test, y_test_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR\n",
      "Training SVM\n",
      "Training NB\n",
      "Training KNN\n",
      "Training XGB\n",
      "Training RF\n",
      "F1: 0.985 | Pr: 0.980 | Re: 0.989 | AUC: 0.999 | Accuracy: 0.985 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "lr = SGDClassifier(loss = 'log', alpha = 0.1, penalty = 'elasticnet')\n",
    "svm = SVC(C = 10, kernel = 'poly', degree = 2, probability = True)\n",
    "nb = MultinomialNB(alpha = 10000, class_prior = [0.5, 0.5])\n",
    "knn = KNeighborsClassifier(n_neighbors = 7, weights = 'distance', n_jobs = 2)\n",
    "rf = RandomForestClassifier(n_estimators = 250, min_samples_split = 5, max_depth = 15,  n_jobs = -1)\n",
    "xgb = XGBClassifier(n_estimators = 100, learning_rate = 0.3, max_depth = 1, n_jobs = -1)\n",
    "\n",
    "model_dict = dict(zip(['LR', 'SVM', 'NB', 'KNN', 'XGB', 'RF'], [lr, svm, nb, knn, xgb, rf]))\n",
    "\n",
    "for model_name, model in model_dict.items():\n",
    "    print('Training {}'.format(model_name))\n",
    "    if model_name == 'XGB':\n",
    "        model.fit(train_features.todense(), y_train)\n",
    "    else:\n",
    "        model.fit(train_features, y_train)\n",
    "\n",
    "model_weights = {   'LR' : 0.9,\n",
    "                    'SVM' : 0.9,\n",
    "                    'NB' : 0.8,\n",
    "                    'KNN' : 0.75,\n",
    "                    'RF' : 0.75,\n",
    "                    'XGB' : 0.6,\n",
    "                    'simple_nn' : 0.7\n",
    "}\n",
    "\n",
    "y_pred_prob = 0\n",
    "\n",
    "for model_name, model in model_dict.items():\n",
    "    if model_name == 'XGB':\n",
    "        y_pred_prob += (model.predict_proba(test_features.todense())[:,1] * model_weights[model_name])\n",
    "    else:\n",
    "        y_pred_prob += (model.predict_proba(test_features)[:,1] * model_weights[model_name])\n",
    "\n",
    "y_pred_prob += (simple_nn.predict(test_features.todense()).ravel() * model_weights['simple_nn'])\n",
    "y_pred_prob /= sum(model_weights.values())\n",
    "\n",
    "print_model_metrics(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_voting_clf(model_weights):\n",
    "    y_pred_prob = 0\n",
    "\n",
    "    for model_name, model in model_dict.items():\n",
    "        if model_name == 'XGB':\n",
    "            y_pred_prob += (model.predict_proba(test_features.todense())[:,1] * model_weights[model_name])\n",
    "        else:   \n",
    "            y_pred_prob += (model.predict_proba(test_features)[:,1] * model_weights[model_name])\n",
    "\n",
    "    #y_pred_prob += (simple_nn.get_preds(ds_type = DatasetType.Valid)[0].numpy()[:,0] * model_weights['simple_nn'])\n",
    "    y_pred_prob += (simple_nn.predict(test_features.todense()).ravel() * model_weights['simple_nn'])\n",
    "    y_pred_prob /= sum(model_weights.values())\n",
    "    f1 = print_model_metrics(y_test, y_pred_prob, return_metrics = True, verbose = 0)[0]\n",
    "    return {'loss' : -f1, 'status' : STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:25<00:00,  5.05s/trial, best loss: -0.985352730171383] \n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "trials = Trials()\n",
    "model_weights = fmin(run_voting_clf,\n",
    "    space= {\n",
    "        'LR' : hp.uniform('LR', 0, 1),\n",
    "        'SVM' : hp.uniform('SVM', 0, 1),\n",
    "        'NB' : hp.uniform('NB', 0, 1),\n",
    "        'KNN' : hp.uniform('KNN', 0, 1),\n",
    "        'RF' : hp.uniform('RF', 0, 1),\n",
    "        'XGB' : hp.uniform('XGB', 0, 1),\n",
    "        'simple_nn' : hp.uniform('simple_nn', 0, 1),\n",
    "    },\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=5,\n",
    "    trials = trials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.983 | Pr: 0.983 | Re: 0.984 | AUC: 0.999 | Accuracy: 0.983 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_weights = {'KNN': 0.7866810233035141,\n",
    " 'LR': 0.8036572275670447,\n",
    " 'NB': 0.9102009774357307,\n",
    " 'RF': 0.1559824350958057,\n",
    " 'SVM': 0.9355079606348642,\n",
    " 'XGB': 0.33469066125332436,\n",
    " 'simple_nn': 0.000545264707939086}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred_prob = 0\n",
    "for model_name, model in model_dict.items():\n",
    "    if model_name == 'XGB':\n",
    "        y_pred_prob += (model.predict_proba(test_features.todense())[:,1] * model_weights[model_name])\n",
    "    else:   \n",
    "        y_pred_prob += (model.predict_proba(test_features)[:,1] * model_weights[model_name])\n",
    "\n",
    "y_pred_prob += (simple_nn.predict(test_features.todense()).ravel() * model_weights['simple_nn'])\n",
    "y_pred_prob /= sum(model_weights.values())\n",
    "print_model_metrics(y_test, y_pred_prob, confusion = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = precision_recall_curve(y_test, y_pred_prob, pos_label = 1)\n",
    "    \n",
    "#Find the threshold value that gives the best F1 Score\n",
    "best_f1_index =np.argmax([calc_f1(p_r) for p_r in zip(precision, recall)])\n",
    "best_threshold, best_precision, best_recall = threshold[best_f1_index], precision[best_f1_index], recall[best_f1_index]\n",
    "\n",
    "# Calulcate predictions based on the threshold value\n",
    "y_test_pred = np.where(y_test_prob > best_threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_idx = y_test != y_test_pred\n",
    "high_confidence_indices = np.argsort(y_test_prob[misclassified_idx])[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title : Like Bats, Shrews Let Echoes Be Their Guide\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.9602175934546525\n",
      "----------\n",
      "Title : Just Browsing? A Web Store May Follow You Out the Door\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.9614956922582023\n",
      "----------\n",
      "Title : Florida Pharmacy Admits Error That Might Have Killed Polo Ponies\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.971754878830899\n",
      "----------\n",
      "Title : Curlers Prove Not All Brazilian Sweepers Play Soccer\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.9765613662020515\n",
      "----------\n",
      "Title : Evidence That Mice Produce Egg Cells After Birth\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.9843639222791714\n",
      "----------\n",
      "Title : Remembering Srebrenice massacre\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.9882503977035892\n",
      "----------\n",
      "Title : Kosher Label Missing From Girl Scout Cookies\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.9923747465122486\n",
      "----------\n",
      "Title : Is This a Shakespeare Which I See Before Me?\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.9979251814662323\n",
      "----------\n",
      "Title : What Do Dreams Mean? Whatever Your Bias Says\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.9981359395288841\n",
      "----------\n",
      "Title : Darwinism Must Die So That Evolution May Live\n",
      "Label : not-clickbait\n",
      "Predicted Probability : 0.9991137473682477\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for idx in high_confidence_indices:\n",
    "    print('Title : {}'.format(test[misclassified_idx].title.values[idx]))\n",
    "    print('Label : {}'.format(test[misclassified_idx].label.values[idx]))\n",
    "    print('Predicted Probability : {}'.format(y_test_prob[misclassified_idx][idx]))\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Knicks Try Out Guard Morris Almond and Like What They See',\n",
       "       'US military to withdraw military trainers from Pakistan',\n",
       "       'Charles Manson releases album under free license',\n",
       "       'Sri Lanka Orders Halt to Fighting Circled Rebels',\n",
       "       'Stopgap at Shortstop? Boston Hopes for More',\n",
       "       'Plan to Make Gowanus Canal a Superfund Site Draws Opposition',\n",
       "       'Two Knicks Who Are Worth Keeping', 'AOL to launch VoIP service',\n",
       "       'Federal response to Katrina a \"national disgrace\"',\n",
       "       'Evolutionary biology labs at University of Colorado threatened'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.label.values == 'not-clickbait'].sample(10).title.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
