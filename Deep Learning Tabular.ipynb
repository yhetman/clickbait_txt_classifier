{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starts with number....\n",
      "Clickbait Phrases....\n",
      "Clickbait re....\n",
      "Num dots....\n",
      "Text Features....\n",
      "Punctuation....\n",
      "Word ratios....\n",
      "Sentiment Scores....\n",
      "Readability Scores....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa11b0dbf80471f9b88ee8095c75b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dce8e5fd68a4ae690c696e2ee18631e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Glove.....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52f9e3628b54d9a87a83d15ea708fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded63a791bde44fba43eb3bd22cbcc0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from utility_funcitons import *\n",
    "from feature_selection import *\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train_features, test_features, feature_names = featurize(train, test, 'tfidf_glove')\n",
    "\n",
    "y_train = np.where(train.label.values == 'clickbait', 1, 0)\n",
    "y_test = np.where(test.label.values == 'clickbait', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "\n",
    "def adjusted_f1(y_true, y_prob):\n",
    "    f1 = print_model_metrics(y_true, y_prob, verbose = 0, return_metrics = True)[0]\n",
    "    return f1\n",
    "\n",
    "score = make_scorer(adjusted_f1, greater_is_better = True, needs_proba = True)\n",
    "\n",
    "X = sparse.vstack((train_features, test_features))\n",
    "test_fold = [-1 for _ in range(train_features.shape[0])] + [0 for _ in range(test_features.shape[0])]\n",
    "y = np.concatenate([y_train, y_test])\n",
    "ps = PredefinedSplit(test_fold)\n",
    "\n",
    "def run_grid_search(model, params, x_train, y_train):\n",
    "    grid = GridSearchCV(model, params, cv = ps, n_jobs = 4, scoring = score, verbose = 0, refit = False)\n",
    "    grid.fit(x_train, y_train)\n",
    "    return (grid.best_params_, grid.best_score_)\n",
    "\n",
    "\n",
    "def fit_n_times(model, x_train, y_train, x_test, y_test, n_iters = 10):\n",
    "    metrics = np.zeros(5)\n",
    "    for _ in range(n_iters):\n",
    "        model.fit(x_train, y_train)\n",
    "        y_test_prob = model.predict_proba(x_test)[:,1]\n",
    "        metrics += print_model_metrics(y_test, y_test_prob, verbose = False, return_metrics = True)\n",
    "    metrics /=10\n",
    "    print('F1: {:.3f} | Pr: {:.3f} | Re: {:.3f} | AUC: {:.3f} | Accuracy: {:.3f} \\n'.format(*metrics))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 150)               18000     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 150)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               15100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,201\n",
      "Trainable params: 33,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "58/79 [=====================>........] - ETA: 0s - loss: 0.4170 - accuracy: 0.8416\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96950, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "79/79 [==============================] - 2s 15ms/step - loss: 0.3474 - accuracy: 0.8701 - val_loss: 0.1014 - val_accuracy: 0.9695\n",
      "Epoch 2/40\n",
      "70/79 [=========================>....] - ETA: 0s - loss: 0.0956 - accuracy: 0.9672\n",
      "Epoch 00002: val_accuracy improved from 0.96950 to 0.97660, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "79/79 [==============================] - 1s 13ms/step - loss: 0.0951 - accuracy: 0.9673 - val_loss: 0.0680 - val_accuracy: 0.9766\n",
      "Epoch 3/40\n",
      "71/79 [=========================>....] - ETA: 0s - loss: 0.0700 - accuracy: 0.9762\n",
      "Epoch 00003: val_accuracy improved from 0.97660 to 0.97935, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 0.0687 - accuracy: 0.9766 - val_loss: 0.0582 - val_accuracy: 0.9793\n",
      "Epoch 4/40\n",
      "75/79 [===========================>..] - ETA: 0s - loss: 0.0646 - accuracy: 0.9761\n",
      "Epoch 00004: val_accuracy improved from 0.97935 to 0.97975, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 0.0653 - accuracy: 0.9759 - val_loss: 0.0573 - val_accuracy: 0.9797\n",
      "Epoch 5/40\n",
      "64/79 [=======================>......] - ETA: 0s - loss: 0.0566 - accuracy: 0.9808\n",
      "Epoch 00005: val_accuracy improved from 0.97975 to 0.98235, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 0.0548 - accuracy: 0.9816 - val_loss: 0.0479 - val_accuracy: 0.9823\n",
      "Epoch 6/40\n",
      "68/79 [========================>.....] - ETA: 0s - loss: 0.0522 - accuracy: 0.9815\n",
      "Epoch 00006: val_accuracy improved from 0.98235 to 0.98310, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "79/79 [==============================] - 1s 17ms/step - loss: 0.0522 - accuracy: 0.9812 - val_loss: 0.0478 - val_accuracy: 0.9831\n",
      "Epoch 7/40\n",
      "72/79 [==========================>...] - ETA: 0s - loss: 0.0535 - accuracy: 0.9814\n",
      "Epoch 00007: val_accuracy did not improve from 0.98310\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9806 - val_loss: 0.0517 - val_accuracy: 0.9807\n",
      "Epoch 8/40\n",
      "55/79 [===================>..........] - ETA: 0s - loss: 0.0516 - accuracy: 0.9821\n",
      "Epoch 00008: val_accuracy improved from 0.98310 to 0.98485, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 0.0510 - accuracy: 0.9818 - val_loss: 0.0424 - val_accuracy: 0.9848\n",
      "Epoch 9/40\n",
      "68/79 [========================>.....] - ETA: 0s - loss: 0.0446 - accuracy: 0.9836\n",
      "Epoch 00009: val_accuracy did not improve from 0.98485\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.9836 - val_loss: 0.0463 - val_accuracy: 0.9826\n",
      "Epoch 10/40\n",
      "72/79 [==========================>...] - ETA: 0s - loss: 0.0462 - accuracy: 0.9826\n",
      "Epoch 00010: val_accuracy did not improve from 0.98485\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9828 - val_loss: 0.0458 - val_accuracy: 0.9833\n",
      "Epoch 11/40\n",
      "75/79 [===========================>..] - ETA: 0s - loss: 0.0474 - accuracy: 0.9830\n",
      "Epoch 00011: val_accuracy improved from 0.98485 to 0.98495, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 0.0474 - accuracy: 0.9827 - val_loss: 0.0417 - val_accuracy: 0.9850\n",
      "Epoch 12/40\n",
      "73/79 [==========================>...] - ETA: 0s - loss: 0.0430 - accuracy: 0.9843\n",
      "Epoch 00012: val_accuracy did not improve from 0.98495\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9843 - val_loss: 0.0577 - val_accuracy: 0.9781\n",
      "Epoch 13/40\n",
      "67/79 [========================>.....] - ETA: 0s - loss: 0.0458 - accuracy: 0.9832\n",
      "Epoch 00013: val_accuracy improved from 0.98495 to 0.98560, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "79/79 [==============================] - 1s 14ms/step - loss: 0.0428 - accuracy: 0.9843 - val_loss: 0.0421 - val_accuracy: 0.9856\n",
      "Epoch 14/40\n",
      "73/79 [==========================>...] - ETA: 0s - loss: 0.0402 - accuracy: 0.9867\n",
      "Epoch 00014: val_accuracy did not improve from 0.98560\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 0.0421 - val_accuracy: 0.9845\n",
      "Epoch 15/40\n",
      "55/79 [===================>..........] - ETA: 0s - loss: 0.0437 - accuracy: 0.9828\n",
      "Epoch 00015: val_accuracy did not improve from 0.98560\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 0.9845 - val_loss: 0.1180 - val_accuracy: 0.9563\n",
      "Epoch 16/40\n",
      "71/79 [=========================>....] - ETA: 0s - loss: 0.0505 - accuracy: 0.9814\n",
      "Epoch 00016: val_accuracy did not improve from 0.98560\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9820 - val_loss: 0.0400 - val_accuracy: 0.9852\n",
      "Epoch 17/40\n",
      "73/79 [==========================>...] - ETA: 0s - loss: 0.0395 - accuracy: 0.9861\n",
      "Epoch 00017: val_accuracy improved from 0.98560 to 0.98590, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "79/79 [==============================] - 1s 13ms/step - loss: 0.0400 - accuracy: 0.9861 - val_loss: 0.0397 - val_accuracy: 0.9859\n",
      "Epoch 18/40\n",
      "74/79 [===========================>..] - ETA: 0s - loss: 0.0374 - accuracy: 0.9862\n",
      "Epoch 00018: val_accuracy did not improve from 0.98590\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.9862 - val_loss: 0.0419 - val_accuracy: 0.9851\n",
      "Epoch 19/40\n",
      "79/79 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9855\n",
      "Epoch 00019: val_accuracy did not improve from 0.98590\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0385 - accuracy: 0.9855 - val_loss: 0.0391 - val_accuracy: 0.9859\n",
      "Epoch 20/40\n",
      "56/79 [====================>.........] - ETA: 0s - loss: 0.0408 - accuracy: 0.9852\n",
      "Epoch 00020: val_accuracy improved from 0.98590 to 0.98665, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 0.0399 - accuracy: 0.9856 - val_loss: 0.0382 - val_accuracy: 0.9866\n",
      "Epoch 21/40\n",
      "69/79 [=========================>....] - ETA: 0s - loss: 0.0414 - accuracy: 0.9864\n",
      "Epoch 00021: val_accuracy did not improve from 0.98665\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9863 - val_loss: 0.0380 - val_accuracy: 0.9866\n",
      "Epoch 22/40\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9871\n",
      "Epoch 00022: val_accuracy did not improve from 0.98665\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 0.9871 - val_loss: 0.0394 - val_accuracy: 0.9861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40\n",
      "56/79 [====================>.........] - ETA: 0s - loss: 0.0394 - accuracy: 0.9852\n",
      "Epoch 00023: val_accuracy did not improve from 0.98665\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9856 - val_loss: 0.0404 - val_accuracy: 0.9852\n",
      "Epoch 24/40\n",
      "56/79 [====================>.........] - ETA: 0s - loss: 0.0448 - accuracy: 0.9835\n",
      "Epoch 00024: val_accuracy did not improve from 0.98665\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9858 - val_loss: 0.0391 - val_accuracy: 0.9860\n",
      "Epoch 25/40\n",
      "72/79 [==========================>...] - ETA: 0s - loss: 0.0331 - accuracy: 0.9883\n",
      "Epoch 00025: val_accuracy did not improve from 0.98665\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0347 - accuracy: 0.9875 - val_loss: 0.0649 - val_accuracy: 0.9764\n",
      "Epoch 26/40\n",
      "74/79 [===========================>..] - ETA: 0s - loss: 0.0383 - accuracy: 0.9849\n",
      "Epoch 00026: val_accuracy did not improve from 0.98665\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 0.9852 - val_loss: 0.0430 - val_accuracy: 0.9840\n",
      "Epoch 27/40\n",
      "54/79 [===================>..........] - ETA: 0s - loss: 0.0343 - accuracy: 0.9877\n",
      "Epoch 00027: val_accuracy did not improve from 0.98665\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9880 - val_loss: 0.0462 - val_accuracy: 0.9822\n",
      "Epoch 28/40\n",
      "55/79 [===================>..........] - ETA: 0s - loss: 0.0326 - accuracy: 0.9898\n",
      "Epoch 00028: val_accuracy did not improve from 0.98665\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.9897 - val_loss: 0.0386 - val_accuracy: 0.9866\n",
      "Epoch 29/40\n",
      "56/79 [====================>.........] - ETA: 0s - loss: 0.0319 - accuracy: 0.9879\n",
      "Epoch 00029: val_accuracy did not improve from 0.98665\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9872 - val_loss: 0.0535 - val_accuracy: 0.9821\n",
      "Epoch 30/40\n",
      "59/79 [=====================>........] - ETA: 0s - loss: 0.0366 - accuracy: 0.9862\n",
      "Epoch 00030: val_accuracy improved from 0.98665 to 0.98680, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "79/79 [==============================] - 1s 13ms/step - loss: 0.0370 - accuracy: 0.9866 - val_loss: 0.0400 - val_accuracy: 0.9868\n",
      "Epoch 31/40\n",
      "58/79 [=====================>........] - ETA: 0s - loss: 0.0387 - accuracy: 0.9859\n",
      "Epoch 00031: val_accuracy did not improve from 0.98680\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9861 - val_loss: 0.0517 - val_accuracy: 0.9805\n",
      "Epoch 32/40\n",
      "76/79 [===========================>..] - ETA: 0s - loss: 0.0332 - accuracy: 0.9880\n",
      "Epoch 00032: val_accuracy did not improve from 0.98680\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.9878 - val_loss: 0.0385 - val_accuracy: 0.9861\n",
      "Epoch 33/40\n",
      "75/79 [===========================>..] - ETA: 0s - loss: 0.0293 - accuracy: 0.9887\n",
      "Epoch 00033: val_accuracy did not improve from 0.98680\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9883 - val_loss: 0.0568 - val_accuracy: 0.9780\n",
      "Epoch 34/40\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0379 - accuracy: 0.9852\n",
      "Epoch 00034: val_accuracy improved from 0.98680 to 0.98695, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 0.0379 - accuracy: 0.9852 - val_loss: 0.0375 - val_accuracy: 0.9869\n",
      "Epoch 35/40\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.9886\n",
      "Epoch 00035: val_accuracy did not improve from 0.98695\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.9886 - val_loss: 0.0427 - val_accuracy: 0.9848\n",
      "Epoch 36/40\n",
      "56/79 [====================>.........] - ETA: 0s - loss: 0.0350 - accuracy: 0.9867\n",
      "Epoch 00036: val_accuracy did not improve from 0.98695\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0326 - accuracy: 0.9875 - val_loss: 0.0492 - val_accuracy: 0.9817\n",
      "Epoch 37/40\n",
      "54/79 [===================>..........] - ETA: 0s - loss: 0.0360 - accuracy: 0.9863\n",
      "Epoch 00037: val_accuracy did not improve from 0.98695\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9871 - val_loss: 0.0387 - val_accuracy: 0.9860\n",
      "Epoch 38/40\n",
      "55/79 [===================>..........] - ETA: 0s - loss: 0.0299 - accuracy: 0.9901\n",
      "Epoch 00038: val_accuracy did not improve from 0.98695\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0285 - accuracy: 0.9903 - val_loss: 0.0461 - val_accuracy: 0.9848\n",
      "Epoch 39/40\n",
      "54/79 [===================>..........] - ETA: 0s - loss: 0.0334 - accuracy: 0.9876\n",
      "Epoch 00039: val_accuracy did not improve from 0.98695\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.9861 - val_loss: 0.0431 - val_accuracy: 0.9850\n",
      "Epoch 40/40\n",
      "78/79 [============================>.] - ETA: 0s - loss: 0.0309 - accuracy: 0.9887\n",
      "Epoch 00040: val_accuracy improved from 0.98695 to 0.98725, saving model to ./saved_models\n",
      "INFO:tensorflow:Assets written to: ./saved_models/assets\n",
      "79/79 [==============================] - 1s 12ms/step - loss: 0.0308 - accuracy: 0.9887 - val_loss: 0.0391 - val_accuracy: 0.9872\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 40\n",
    "\n",
    "simple_nn = Sequential()\n",
    "simple_nn.add(Dense(150, activation='relu', input_shape=(119,)))\n",
    "simple_nn.add(Dropout(0.2))\n",
    "simple_nn.add(Dense(100, activation='relu'))\n",
    "simple_nn.add(Dropout(0.2))\n",
    "simple_nn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "simple_nn.summary()\n",
    "\n",
    "simple_nn.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('./saved_models', monitor = 'val_accuracy', verbose = 1, save_best_only=True)\n",
    "\n",
    "history = simple_nn.fit(train_features.todense(), y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks = [checkpoint],\n",
    "                    validation_data=(test_features.todense(), y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.988 | Pr: 0.985 | Re: 0.991 | AUC: 0.999 | Accuracy: 0.988 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "simple_nn = load_model('./saved_models')\n",
    "\n",
    "y_pred_prob = simple_nn.predict(test_features.todense())\n",
    "print_model_metrics(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.989 | Pr: 0.985 | Re: 0.992 | AUC: 0.999 | Accuracy: 0.989 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "svm = SVC(C = 10, kernel = 'poly', degree = 2, probability = True, verbose = 0)\n",
    "\n",
    "svm_bag = BaggingClassifier(svm, n_estimators = 200, max_features = 0.9, max_samples = 1.0, bootstrap_features = False, bootstrap = True, n_jobs = 1, verbose = 0)\n",
    "\n",
    "svm_bag.fit(train_features, y_train)\n",
    "y_test_prob = svm_bag.predict_proba(test_features)[:,1]\n",
    "print_model_metrics(y_test, y_test_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR\n",
      "Training SVM\n",
      "Training NB\n",
      "Training KNN\n",
      "Training XGB\n",
      "Training RF\n",
      "F1: 0.989 | Pr: 0.988 | Re: 0.991 | AUC: 0.999 | Accuracy: 0.989 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "lr = SGDClassifier(loss = 'log', alpha = 0.1, penalty = 'elasticnet')\n",
    "svm = SVC(C = 10, kernel = 'poly', degree = 2, probability = True)\n",
    "nb = MultinomialNB(alpha = 10000, class_prior = [0.5, 0.5])\n",
    "knn = KNeighborsClassifier(n_neighbors = 7, weights = 'distance', n_jobs = 2)\n",
    "rf = RandomForestClassifier(n_estimators = 250, min_samples_split = 5, max_depth = 15,  n_jobs = -1)\n",
    "xgb = XGBClassifier(n_estimators = 100, learning_rate = 0.3, max_depth = 1, n_jobs = -1)\n",
    "\n",
    "model_dict = dict(zip(['LR', 'SVM', 'NB', 'KNN', 'XGB', 'RF'], [lr, svm, nb, knn, xgb, rf]))\n",
    "\n",
    "for model_name, model in model_dict.items():\n",
    "    print('Training {}'.format(model_name))\n",
    "    if model_name == 'XGB':\n",
    "        model.fit(train_features.todense(), y_train)\n",
    "    else:\n",
    "        model.fit(train_features, y_train)\n",
    "\n",
    "model_weights = {   'LR' : 0.9,\n",
    "                    'SVM' : 0.9,\n",
    "                    'NB' : 0.8,\n",
    "                    'KNN' : 0.75,\n",
    "                    'RF' : 0.75,\n",
    "                    'XGB' : 0.6,\n",
    "                    'simple_nn' : 0.7\n",
    "}\n",
    "\n",
    "y_pred_prob = 0\n",
    "\n",
    "for model_name, model in model_dict.items():\n",
    "    if model_name == 'XGB':\n",
    "        y_pred_prob += (model.predict_proba(test_features.todense())[:,1] * model_weights[model_name])\n",
    "    else:\n",
    "        y_pred_prob += (model.predict_proba(test_features)[:,1] * model_weights[model_name])\n",
    "\n",
    "y_pred_prob += (simple_nn.predict(test_features.todense()).ravel() * model_weights['simple_nn'])\n",
    "y_pred_prob /= sum(model_weights.values())\n",
    "\n",
    "print_model_metrics(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_voting_clf(model_weights):\n",
    "    y_pred_prob = 0\n",
    "\n",
    "    for model_name, model in model_dict.items():\n",
    "        if model_name == 'XGB':\n",
    "            y_pred_prob += (model.predict_proba(test_features.todense())[:,1] * model_weights[model_name])\n",
    "        else:   \n",
    "            y_pred_prob += (model.predict_proba(test_features)[:,1] * model_weights[model_name])\n",
    "\n",
    "    #y_pred_prob += (simple_nn.get_preds(ds_type = DatasetType.Valid)[0].numpy()[:,0] * model_weights['simple_nn'])\n",
    "    y_pred_prob += (simple_nn.predict(test_features.todense()).ravel() * model_weights['simple_nn'])\n",
    "    y_pred_prob /= sum(model_weights.values())\n",
    "    f1 = print_model_metrics(y_test, y_pred_prob, return_metrics = True, verbose = 0)[0]\n",
    "    return {'loss' : -f1, 'status' : STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 65/500 [37:22<4:07:01, 34.07s/trial, best loss: -0.9897494874743736]"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "trials = Trials()\n",
    "model_weights = fmin(run_voting_clf,\n",
    "    space= {\n",
    "        'LR' : hp.uniform('LR', 0, 1),\n",
    "        'SVM' : hp.uniform('SVM', 0, 1),\n",
    "        'NB' : hp.uniform('NB', 0, 1),\n",
    "        'KNN' : hp.uniform('KNN', 0, 1),\n",
    "        'RF' : hp.uniform('RF', 0, 1),\n",
    "        'XGB' : hp.uniform('XGB', 0, 1),\n",
    "        'simple_nn' : hp.uniform('simple_nn', 0, 1),\n",
    "\n",
    "\n",
    "    },\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=500,\n",
    "    trials = trials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = {'KNN': 0.7866810233035141,\n",
    " 'LR': 0.8036572275670447,\n",
    " 'NB': 0.9102009774357307,\n",
    " 'RF': 0.1559824350958057,\n",
    " 'SVM': 0.9355079606348642,\n",
    " 'XGB': 0.33469066125332436,\n",
    " 'simple_nn': 0.000545264707939086}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred_prob = 0\n",
    "for model_name, model in model_dict.items():\n",
    "    if model_name == 'XGB':\n",
    "        y_pred_prob += (model.predict_proba(test_features.todense())[:,1] * model_weights[model_name])\n",
    "    else:   \n",
    "        y_pred_prob += (model.predict_proba(test_features)[:,1] * model_weights[model_name])\n",
    "\n",
    "y_pred_prob += (simple_nn.predict(test_features.todense()).ravel() * model_weights['simple_nn'])\n",
    "y_pred_prob /= sum(model_weights.values())\n",
    "print_model_metrics(y_test, y_pred_prob, confusion = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = precision_recall_curve(y_test, y_pred_prob, pos_label = 1)\n",
    "    \n",
    "#Find the threshold value that gives the best F1 Score\n",
    "best_f1_index =np.argmax([calc_f1(p_r) for p_r in zip(precision, recall)])\n",
    "best_threshold, best_precision, best_recall = threshold[best_f1_index], precision[best_f1_index], recall[best_f1_index]\n",
    "\n",
    "# Calulcate predictions based on the threshold value\n",
    "y_test_pred = np.where(y_test_prob > best_threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_idx = y_test != y_test_pred\n",
    "high_confidence_indices = np.argsort(y_test_prob[misclassified_idx])[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in high_confidence_indices:\n",
    "    print('Title : {}'.format(test[misclassified_idx].title.values[idx]))\n",
    "    print('Label : {}'.format(test[misclassified_idx].label.values[idx]))\n",
    "    print('Predicted Probability : {}'.format(y_test_prob[misclassified_idx][idx]))\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test.label.values == 'not-clickbait'].sample(10).title.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
